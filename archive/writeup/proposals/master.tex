\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}

% amsmath package, useful for mathematical formulas
\usepackage{amsmath}
% amssymb package, useful for mathematical symbols
\usepackage{amssymb}

% hyperref package, useful for hyperlinks
\usepackage{hyperref}

% graphicx package, useful for including eps and pdf graphics
% include graphics with the command \includegraphics
\usepackage{graphicx}

\usepackage{multirow}

% Sweave(-like)
\usepackage{fancyvrb}
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontshape=sl}
\newenvironment{Schunk}{}{}
\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}
\newenvironment{CodeChunk}{}{}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}

\usepackage{color}

% Text layout
\topmargin 0.0cm
\oddsidemargin 0.5cm
\evensidemargin 0.5cm
\textwidth 16cm
\textheight 21cm

% Bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,justification=raggedright]{caption}

% Remove brackets from numbering in List of References
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Leave date blank
\date{}

\pagestyle{myheadings}

\begin{document}

% Title must be 150 characters or less
\begin{flushleft}
{\Large
\textbf{Quantifying Human Genetic Variation At Scale}
}
\\
\smallskip
  {
    \large Research Computing Center, University of Chicago
  }
\\
  {
    \large Research II Allocation Request
  }
% Insert Author names, affiliations and corresponding author email.
  \\
\smallskip
  Matthew Stephens Lab\textsuperscript{1,2*}\\
\bf{1} Department of Statistics, University of Chicago,  Chicago,  IL,  USA
\\
\bf{2} Department of Human Genetics, University of Chicago,  Chicago,  IL,  USA
\\

\textasteriskcentered{} E-mail:   \href{mailto:mstephens@uchicago.edu}{\nolinkurl{mstephens@uchicago.edu}}

\end{flushleft}

\section*{Introduction}

In our group, we develop and apply statistical methods to understand
the genetic basis and biological mechanism of complex human
phenotypes. The generation of massive data sets via next-generation
genome sequencing efforts promises huge payoffs in the understanding
of human phenotypic variation and human disease as it enables a
transition from ad hoc hypothesis-driven experimentation to
comprehensive, principled investigation, but it also creates new
challenges in the scale of analysis that we hope to address in our
work ahead.

We propose two high-impact computational projects on RCC's Midway
cluster in which we apply Bayesian statistical methods developed in
our group to full-scale genomic data sets. Each project uses a
different mechanistic basis to extract new insight from this deluge of
genomic data. The first project uses known biological pathways and
existing, publicly available genome-wide association study (GWAS)
summary statistics to improve our ability to resolve new genetic
determinants of human phenotypes and disease. We request 600,000
service units (SUs) and will use our own storage assets on Midway to
complete this project. The second project focuses on the ways in which
genetic varation can specifically modulate gene expression; this work
relies on the novel dataset currently being acquired by the Genotype
Tissue Expression (GTEx) consortium. This project will require 190,000
SUs in addition to 1 TB of persistent storage. In total, we request
790,000 service units (SUs) and 1 TB of persistent storage.

\section*{Constructing an atlas of biological pathways and genetic variants}

\subsection*{Research goals and potential
impact}\label{research-goals-and-the-potential-impact}
\addcontentsline{toc}{section}{Research goals and potential impact}

Recently, curated knowledge-bases of biological pathways have been
created and shared \cite{demir.cary.ea:biopax}. Peer-reviewed pathways
effectively organize functionally related genes that are involved in
the development of certain complex traits. Leveraging these public
assets in genome-wide association studies (GWAS) can help gain insight
into the underlying biology of complex traits, which can then be
applied to improve the health of people.

Motivated by this observation, we have proposed an efficient Bayesian
approach \cite{carbonetto.stephens:integrated} to integrate pathway
enrichment analysis \cite{wang.li.ea:analysing} with variant
prioritization \cite{cantor.lange.ea:prioritizing}. This method,
however, is limited by the requirement of individual-level genotype
and phenotype data, which are rarely accessible for large GWAS. Using
a recently-developed Bayesian large-scale regression approach
\cite{zhu.stephens:bayesian}, we soften the requirement of
\cite{carbonetto.stephens:integrated}; the modified method relies
solely on publicly available GWAS summary statistics. Hence, we can
easily apply our methods on a wide range of human phenotypes including
anthropometric traits (e.g.~adult height), immune traits (e.g.~Crohn's
disease), metabolic phenotypes (e.g.~blood lipid levels), and
psychiatric diseases (e.g.~schizophrenia). Our aim is to release an
``atlas'' of biological pathways and genetic variants across multiple
complex human traits using GWAS summary statistics.

The atlas is likely to be useful for basic, translational, and
clinical research in biology and medicine. First, our comprehensive
results can help statisticians and computational biologists benchmark
their methods for pathway analysis and/or variant prioritization.
Second, our data-driven method links loci and pathways to pathogenesis
jointly and therefore is statistically more powerful than conventional
analysis (e.g.~GWAS) for uncovering disease risk factors, which might
suggest innovative treatment targets for experimental biologists and
physicians.  The benefit of pathway-based analysis has been
empirically validated in complex disease studies. For example, the
PI3K/RAS pathway is deregulated in 45\% of 316 ovarian cancer cases
\cite{cancer-genome-atlas-research-network:integrated} even though all
seven genes in this pathway have relatively weak signals
(0.5\%--18\%).

\subsection*{Results from previous
allocations}\label{xiang-results-from-previous-allocations}
\addcontentsline{toc}{section}{Results from previous allocations}

Our previous approach \cite{carbonetto.stephens:integrated} requires
individual-level genotypes and phenotypes. To circumvent the limited
availability of individual-level data, our new method is built on a
Bayesian regression model \cite{zhu.stephens:bayesian} that only
requires summary data. We apply the two methods to the Wellcome Trust
Case Control Consortium (WTCCC) GWAS data for Crohn's disease
\cite{wellcome-trust-case-control-consortium:genome-wide}. The summary
statistics-based method obtains results comparable to the analysis
using individual-level data (Figure \ref{xiang-figure}).
\begin{figure}
\begin{center}
\includegraphics[scale=0.5]{cd_results.png}
  \caption{Comparison of \cite{carbonetto.stephens:integrated} and
    \cite{zhu.stephens:bayesian} for Crohn's disease. BF and SBF
    measure the strength of pathway enrichment in
    \cite{carbonetto.stephens:integrated} and
    \cite{zhu.stephens:bayesian} respectively. Both methods were run
    with 3,157 pathways.}
  \label{xiang-figure}
\end{center}
\end{figure}

Our new method uses a parallel algorithm based on mean-field
variational approximation \cite{wainwright.jordan:graphical}. Hence,
compared with the serial implementation in
\cite{carbonetto.stephens:integrated}, the new method is more
scalable. Table \ref{scale} reports the timing results of two
methods with varying number of CPUs on two experiments.

\begin{table}[h]
\centering
\begin{tabular}{clcll}
\hline
\multicolumn{1}{l}{\multirow{2}{*}{Experiment}} & \multirow{2}{*}{Partition} & \multicolumn{1}{l}{\multirow{2}{*}{Number of CPUs}} & \multicolumn{2}{c}{Wall time (s)}                \\
\multicolumn{1}{l}{}                            &                            & \multicolumn{1}{l}{}                                & Carbonetto-Stephens (2013) & Zhu-Stephens (2015) \\
\hline
1                                               & \texttt{westmere}                   & 1                                                   & 403.364                    & 387.661             \\
1                                               & \texttt{westmere}                   & 2                                                   & 402.207                    & 282.357             \\
2                                               & \texttt{bigmem}                     & 1                                                   & 1416.164                   & 2083.683            \\
2                                               & \texttt{westmere}                   & 2                                                   & 1209.082                   & 1035.426            \\
2                                               & \texttt{westmere}                   & 4
 & 1166.437                   & 720.544 \\
\hline
\end{tabular}
\caption{Scaling results of two methods. Experiment 1 consists of
  11,861 genetic variants on two chromosomes. Experiment 2 consists of
  30,939 genetic variants on four chromosomes.\label{scale}}
\end{table}

\subsection*{Estimate of requested
resources}\label{xiang-estimate-of-requested-resources}
\addcontentsline{toc}{section}{Estimate of requested resources}

To create the pathway-phenotype atlas, we will retrieve 4,000 curated
biological pathways from web databases and then apply our new method
on 30 full sets of publicly available GWAS summary statistics, each
including 1--2 $ \times 10^6 $ genetic variants. For each GWAS
dataset, our analysis will consist of two phases. Computation in Phase
I will be performed on all genetic variants across the genome, using a
multi-threaded implementation. Phase II will only use genetic variants
assigned to pathways, and, depending on the pathway size, the number
of variants can be in the $ 10^2 $ -- $ 10^4 $ range. Both Phase I and
II can be further decomposed into multiple concurrent jobs on Midway.

Based on our pilot experiments performed under our previously accepted
proposals on Midway, analyzing a typical set of GWAS summary
statistics requires 20,000 SUs, broken down as follows. Phase I
requires 16--20 CPUs on one node (\texttt{sandyb} or \texttt{ivyb}),
1--3 GB memory per CPU, and 600--650 hours of wall time. Phase II will
require 2--4 CPUs on one node (\texttt{sandyb} or \texttt{ivyb}),
0.5--5 GB memory per CPU, and 1,500--1,800 hours of wall time. In
addition, use of a \texttt{bigmem} node is needed to pre-process the
data set, which requires 1 CPU with 150--200 GB memory and 20--30
hours of wall time.

Applying this computational workflow to the 30 publicly available sets
of GWAS summary statistics justifies the request for 600,000 SUs to
generate the proposed atlas of biological pathways and genetic
variants. All of the GWAS data sets as well as the results of this
workflow can be stored in existing space we have purchased via the
Cluster Partnership Program, so we are not requesting additional
persistent storage for this project.

\section*{Applying multi-tissue methods to GTEx expression data}

\subsection*{Research goals and potential
impact}\label{gao-research-goals-and-the-potential-impact}
\addcontentsline{toc}{section}{Research goals and potential impact}

Variation in gene expression plays a crucial role in the etiology of
complex human disease.  Understanding the genetic factors that
underpin the quantitative levels of gene expression (known as
expression quantitative trait loci, or eQTLs) provides intermediate
insight into biological basis for disease associations identified in
genetic mapping studies such as GWAS \cite{albert.kruglyak:role}.  To
date, most efforts on eQTL discovery have focused on a given genetic
variant's contribution to gene expression within a single cell type or
tissue.  Although the importance of shared eQTL between human cells
and tissues has been well acknowledged \cite{dimas.ea:common},
multi-cell and multi-tissue analyses remain challenging due to the
lack of adequate data sources and of analytic tools that are both
statistically powerful and computationally efficient.

Recently, the Genotype Tissue Expression (GTEx) Project, a renowned
global research effort aiming at understanding the role of regulatory
variants in multiple tissues, have completed its Pilot Phase
\cite{ardlie.ea:genotype-tissue}.  Our group, as part of the
Statistical Genetics Committee in GTEx, previously developed a
statistical framework that improved power to detect eQTL sharing among
multiple tissues \cite{flutre.wen.ea:statistical}.  However, a
critical drawback of the framework is that its computational time is
proportional to $2^R$ where $R$ is the number of tissues; it becomes
intractable to even consider over ten tissues jointly. On the other
hand, however, the GTEx consortium will release eQTL data on 44
tissues in approximately 900 post-mortem human donors by the end of
2015, a rich and expensively acquired data set that demands a
correspondingly rich analysis in the near future.

\subsection*{Results from previous allocations}\label{gao-results-from-previous-allocations}
\addcontentsline{toc}{section}{Results from previous allocations and
  anticipated tasks for future allocations}

Our previous statistical framework for joint tissue analysis was
applied to the GTEx pilot phase involving nine tissues.  Computations
were performed on the Midway cluster.  The result contributed to the
\textit{Science} paper published in May 2015
\cite{ardlie.ea:genotype-tissue}.

We are actively engaged in devising two independent statistical
approaches to jointly analyze large numbers of tissues.  Once these
new methods are fully developed, we will apply them to the full GTEx
data set upon its release. Furthermore, our methods can potentially be
applied more generally to problems involving assessments of genetic
factors across multiple data sources, a type of data integration
problem of broader interest in the emerging field of genetic data
science. By using lower dimensional spaces of probability measures, we
will avoid the exponential growth in the computational cost of joint
multi-tissue analysis that hampered the scaling of our previous
methods.

In preparing for analysis-ready data-sets, we have developed an
efficient data management framework based on an \texttt{HDF5} file
format.  In a previous allocation on Midway, we processed
approximately $ 5 \times 10^{10} $ lines of text to prepare the
smaller April 2015 GTEx release for analysis. We are expecting a
complete update of source data, and consequently the need to rebuild
the data system, in October 2015.

\subsection*{Estimate of requested
resources}\label{gao-estimate-of-requested-resources}
\addcontentsline{toc}{section}{Estimate of requested resources}

Our request for the GTEx eQTL project is dedicated to three tasks:
ingesting the GTEx data into a format suitable for joint tissue
analysis and the development and production application of two
statistical methods.

Preparing the upcoming October 2015 release of GTEx data for analysis
will involve a workflow that is directly scaled up from our previous
work on the April 2015 release, which contained about half as many
volunteers. Changes in the consortium's pre-release data processing
means that we will need to re-process the full data set. To ingest the
raw data as released by GTEx into a form amenable for analysis will
require 1000 SUs (16 CPUs on one \texttt{sandby} or \texttt{ivb} node
with 1 GB memory per CPU for approximately 60 hours of wall time,
broken into several concurrent jobs) to perform genome-wide single
tissue analysis and to organize this data into our HDF5 system. We
will need another 200 SUs per tissue on a \texttt{bigmem} node (1 CPU
with 100--200 GB of memory for approximately 200 hours per tissue) to
merge and compute summary statistics. This work will thus require
50,000 SUs for the upcoming data processing task. Storing the results
of this processing will require 600 GB of peristent storage.

For the first ``quantitative'' model we are developing, we will need
approximately 200 SUs (16 CPUs on one \texttt{sandyb} or \texttt{ivyb}
node for 12 hours of wall time) to fit the model on a sampling of
50,000 data points, which is about 0.05\% of the total data set. As we
complete development of this model, we will work at this scale to
improve model parameter configurations, requiring a negligible amount
of compuational effort. The limits on the expressiveness of the
quantitative model means that we will ultimately only need to sample
10\% of the total data points in our production work, requiring 40,000
SUs.

For the second ``qualitative'' model, we will develop the model at a
scale of 1\% of the full GTEx data set and scale it to cover 10\% of
the data set in production. Based on experimentation, the first part
of this model will require approximately 20,000 SUs (16 CPUs on one
\texttt{bigmem} node with 200 GB memory for 1250 hours of total wall
time). We are engaged in parallelizing the remaining part of the
qualitative model but estimate that it will consume 60,000 SUs on
\texttt{sandyb} or \texttt{ivyb} nodes. In tuning the model and
implementing its parallel version, we expect non-trivial computational
needs (about 20,000 SUs) as we bring the methods up to scale. Thus,
this second model will consume approximately 100,000 SUs.

Storing the artifacts of these two models will require a further 400
GB of persistent storage, justifying the remainder of our request of
190,000 SUs and 1 TB of persistent storage for this project.

\bibliography{master}{}
\bibliographystyle{unsrt}

\end{document}
