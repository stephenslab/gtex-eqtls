{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Formatting independent eQTL analysis results for MASH posterior calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "I have received from GTEx fine-mapping group independent eQTL data. Here I convert it to MASH input format in order to compute posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Data overview\n",
    "\n",
    "There are two sets of results, from conditional analysis and from DAP-G. Data format is very similar to `fastqtl` output, except that there is an additional first column of tissue name. \n",
    "\n",
    "Here for each data-set take the union of cross tissue results and obtain a list of gene-SNP pair IDs in YAML format, load it to R, and extract directly from the HDF5 database the relevant information. \n",
    "I do it for batches of $K$ genes, obtaining roughly $\\frac{30000}{K}$ batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run Independent_eQTL_Results.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  default\n",
      "\n",
      "Global Workflow Options:\n",
      "  --data data/independent_eQTL/DAPG_pip_gt_0.01-AllTissues.txt (as path)\n",
      "                        A text file containing data-set names\n",
      "  --db fastqtl_to_mash_output/FastQTLSumStats.h5 (as path)\n",
      "                        HDF5 file of the summary statistics database\n",
      "  --batch-size 5000 (as int)\n",
      "                        Batch size\n",
      "\n",
      "Sections\n",
      "  default_1:            Generate batches of gene-SNPs\n",
      "  default_2:            Run data conversion\n"
     ]
    }
   ],
   "source": [
    "! sos run Independent_eQTL_Results.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Format conversion pipeline\n",
    "\n",
    "Commands below processes the two fine-mapping results:\n",
    "\n",
    "```\n",
    "sos run analysis/Independent_eQTL_Results.ipynb default:1 \\\n",
    "    --data data/independent_eQTL/DAPG_pip_gt_0.01-AllTissues.txt\n",
    "sos run analysis/Independent_eQTL_Results.ipynb default:1 \\\n",
    "    --data data/independent_eQTL/ConditionalAnalysis_AllTissues.txt\n",
    "```\n",
    "\n",
    "(and run on cluster:)\n",
    "\n",
    "```\n",
    "sos run analysis/Independent_eQTL_Results.ipynb default:2 \\\n",
    "    --data data/independent_eQTL/DAPG_pip_gt_0.01-AllTissues.txt \\\n",
    "    -c data/fe961153.localhost.yml\n",
    "sos run analysis/Independent_eQTL_Results.ipynb default:2 \\\n",
    "    --data data/independent_eQTL/ConditionalAnalysis_AllTissues.txt \\\n",
    "    -c data/fe961153.localhost.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# A text file containing data-set names\n",
    "parameter: data = path(\"data/independent_eQTL/DAPG_pip_gt_0.01-AllTissues.txt\")\n",
    "# HDF5 file of the summary statistics database\n",
    "parameter: db = path(\"fastqtl_to_mash_output/FastQTLSumStats.h5\")\n",
    "# Batch size\n",
    "parameter: batch_size = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Workflow below extracts batches of YAML files of the format:\n",
    "\n",
    "```\n",
    "gene_name_1: [snp1, snp2, ...]\n",
    "gene_name_2: [snp1, snp2, ...]\n",
    "```\n",
    "\n",
    "They will later be used to extract from the summary statistics database the gene-SNP pairs of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Generate batches of gene-SNPs\n",
    "[default_1]\n",
    "fail_if(not data.is_file(), msg = 'Need data file!')\n",
    "input: data\n",
    "output: dynamic(f\"{data:n}/{data:bn}.batch_*.yaml\")\n",
    "bash: expand = True\n",
    "    mkdir -p {data:n}\n",
    "python: expand = '${ }', stdout = f\"{data:n}/{data:bn}.stdout\"\n",
    "    def write_res(res, batch):\n",
    "        import yaml\n",
    "        fn = f\"${data:n}/${data:bn}.batch_{batch}.yaml\"\n",
    "        with open(fn, 'w') as outfile:\n",
    "            yaml.dump(res, outfile)\n",
    "\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(${_input:r}, sep='\\t', header=0)\n",
    "    #data.sort_values(by=['gene_id', 'variant_id'], inplace=True)\n",
    "    res = dict()\n",
    "    idx = 1\n",
    "    batch = 1\n",
    "    print(\"Start ...\")\n",
    "    for item in set(data['gene_id']):\n",
    "        res[item.rsplit('.',1)[0]] = sorted(set(data.loc[data['gene_id'] == item]['variant_id'].tolist()))\n",
    "        if idx % ${batch_size} == 0:\n",
    "            print(f'batch {batch}')\n",
    "            write_res(res, batch)\n",
    "            batch += 1\n",
    "            res = dict()\n",
    "        idx += 1\n",
    "    if len(res):\n",
    "        write_res(res, batch)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "Workflow below extracts gene-SNP pairs of interest. \n",
    "\n",
    "**FIXME: not all gene-SNPs in the YAML file exist in the summary statistics database!**. Recall that the YAML file contains results from DAP-G / Conditional Regression analysis but I use their ID to extract from the original `fastqtl` results. \n",
    "\n",
    "Possible reasons of inconsistency:\n",
    "\n",
    "1. The two data-sets analyzed slightly different gene-SNP combinations\n",
    "2. **A bug in my `fastqtl` to summary database conversion code!**\n",
    "\n",
    "I saved these inconsistencies in `*.batch_*.stdout`. It prints which gene has fewer SNPs in the summary statistics DB. Most of them are just 1 SNP short. There are not many, anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Run data conversion\n",
    "[default_2]\n",
    "depends: R_library('rhdf5'), R_library('yaml')\n",
    "input: f\"{data:n}/{data:bn}.batch_*.yaml\", group_by = 1, concurrent = True\n",
    "output: f'{_input:n}.rds'\n",
    "task: trunk_workers = 1, queue = 'midway2', walltime = '2h', trunk_size = 1, mem = '4G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", stdout = f'{_output:n}.stdout'\n",
    "    ConvertP2Z <- function(pval, beta) {\n",
    "      z <- abs(qnorm(pval / 2))\n",
    "      z[which(beta < 0)] <- -1 * z[which(beta < 0)]\n",
    "      return(z)\n",
    "    }\n",
    "\n",
    "    GetSS <- function(table, db) {\n",
    "      dat <- rhdf5::h5read(db, table)\n",
    "      dat$\"z\" <- ConvertP2Z(dat$\"pval\", dat$\"beta\")\n",
    "      for (name in c(\"beta\", \"se\", \"pval\", \"z\")) {\n",
    "        dat[[name]] <- as.matrix(t(dat[[name]]))\n",
    "        colnames(dat[[name]]) <- dat$colnames\n",
    "        rownames(dat[[name]]) <- dat$rownames\n",
    "      }\n",
    "      dat$colnames <- dat$rownames <- NULL\n",
    "      ## fastqtl tend to produce nan for betahat zero\n",
    "      ## here I set it to zero as well\n",
    "      dat[['se']][which(is.nan(dat[['se']]))] = 0\n",
    "      return(dat)\n",
    "    }\n",
    "    ##\n",
    "    meta = yaml::read_yaml(${_input:r})\n",
    "    res = list()\n",
    "    for (gene in names(meta)) {\n",
    "      snps = gsub('^chr|_b38$', '', meta[[gene]])\n",
    "      dat = GetSS(gene, ${db:ar})\n",
    "      for (p in names(dat)) {\n",
    "        common_snps = intersect(snps, rownames(dat[[p]]))\n",
    "        snp_diff = length(snps) - length(common_snps)\n",
    "        if (snp_diff > 0 && p == 'beta')\n",
    "          print(paste(gene, 'is', snp_diff, 'SNP short!'))\n",
    "        if (length(common_snps) == 0) {\n",
    "          if (p == 'beta')\n",
    "            print(paste(gene, 'is empty!'))\n",
    "          next\n",
    "        }\n",
    "        dat[[p]] = dat[[p]][common_snps,,drop=F]\n",
    "        rownames(dat[[p]]) = paste0(gene, '_', rownames(dat[[p]]))\n",
    "      }\n",
    "      if (is.null(res$Bhat))\n",
    "        res$Bhat = dat[['beta']]\n",
    "      else\n",
    "        res$Bhat = rbind(res$Bhat, dat[['beta']])\n",
    "      if (is.null(res$Shat))\n",
    "        res$Shat = dat[['se']]\n",
    "      else\n",
    "        res$Shat = rbind(res$Shat, dat[['se']])\n",
    "    }\n",
    "    saveRDS(res, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.20.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
